{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash==1.9.0 (from -r requirements.txt (line 1))\n",
      "Collecting dash-bootstrap-components==0.8.3 (from -r requirements.txt (line 2))\n",
      "Collecting dash-core-components==1.8.0 (from -r requirements.txt (line 3))\n",
      "Collecting dash-daq==0.3.1 (from -r requirements.txt (line 4))\n",
      "Collecting dash-html-components==1.0.2 (from -r requirements.txt (line 5))\n",
      "Collecting dash-renderer==1.2.4 (from -r requirements.txt (line 6))\n",
      "Collecting dash-table==4.6.0 (from -r requirements.txt (line 7))\n",
      "Collecting EMD-signal==0.2.10 (from -r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/35/46fa4230b3a402dd1e39c070ca4d82289f7497ae1a3c223a462e8bf3206a/EMD_signal-0.2.10-py2.py3-none-any.whl\n",
      "Collecting fastdtw==0.3.4 (from -r requirements.txt (line 9))\n",
      "Collecting joblib==0.15.1 (from -r requirements.txt (line 10))\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl\n",
      "Collecting matplotlib==3.0.3 (from -r requirements.txt (line 11))\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting missingno==0.4.2 (from -r requirements.txt (line 12))\n",
      "  Using cached https://files.pythonhosted.org/packages/2b/de/6e4dd6d720c49939544352155dc06a08c9f7e4271aa631a559dfbeaaf9d4/missingno-0.4.2-py3-none-any.whl\n",
      "Collecting numpy==1.18.4 (from -r requirements.txt (line 13))\n",
      "  Using cached https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pandas==1.0.3 (from -r requirements.txt (line 14))\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/71/8f53bdbcbc67c912b888b40def255767e475402e9df64050019149b1a943/pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting plotly==4.8.1 (from -r requirements.txt (line 15))\n",
      "  Using cached https://files.pythonhosted.org/packages/70/56/eabdc7b7187cdb9d6121f6de2831ad5b85f7d002fa4bfe0476dbdb554bf6/plotly-4.8.1-py2.py3-none-any.whl\n",
      "Collecting PyYAML==5.1.1 (from -r requirements.txt (line 16))\n",
      "Collecting jupyter-dash==0.3.1 (from -r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/b9/5f9499a0154124a262c85e3a99033b9b3a20dc3d2707b587f52b32b60d76/jupyter_dash-0.3.1-py3-none-any.whl\n",
      "Collecting scikit-learn==0.23.1 (from -r requirements.txt (line 18))\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting scipy==1.5.0 (from -r requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/06/20/d4410683e4d416a11ebc60138f6d925f571ffcfcc3794baf78fff982c98d/scipy-1.5.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting seaborn==0.10.1 (from -r requirements.txt (line 20))\n",
      "  Using cached https://files.pythonhosted.org/packages/c7/e6/54aaaafd0b87f51dfba92ba73da94151aa3bc179e5fe88fc5dfb3038e860/seaborn-0.10.1-py3-none-any.whl\n",
      "Collecting statsmodels==0.10.1 (from -r requirements.txt (line 21))\n",
      "  Using cached https://files.pythonhosted.org/packages/60/d6/e9859e68e7d6c916fdff7d8e0958a7f5813485c52fc20d061273eaaddb0c/statsmodels-0.10.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting Flask>=1.0.2 (from dash==1.9.0->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl\n",
      "Collecting future (from dash==1.9.0->-r requirements.txt (line 1))\n",
      "Collecting flask-compress (from dash==1.9.0->-r requirements.txt (line 1))\n",
      "Collecting pathos>=0.2.1 (from EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "Collecting numpydoc (from EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/60/1d/9e398c53d6ae27d5ab312ddc16a9ffe1bee0dfdf1d6ec88c40b0ca97582e/numpydoc-1.1.0-py3-none-any.whl\n",
      "Collecting python-dateutil>=2.1 (from matplotlib==3.0.3->-r requirements.txt (line 11))\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib==3.0.3->-r requirements.txt (line 11))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 11))\n",
      "  Using cached https://files.pythonhosted.org/packages/ae/23/147de658aabbf968324551ea22c0c13a00284c4ef49a77002e91f79657b7/kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 11))\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting pytz>=2017.2 (from pandas==1.0.3->-r requirements.txt (line 14))\n",
      "  Using cached https://files.pythonhosted.org/packages/4f/a4/879454d49688e2fad93e59d7d4efda580b783c745fd2ec2a3adf87b0808d/pytz-2020.1-py2.py3-none-any.whl\n",
      "Collecting retrying>=1.3.3 (from plotly==4.8.1->-r requirements.txt (line 15))\n",
      "Collecting six (from plotly==4.8.1->-r requirements.txt (line 15))\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting ipykernel (from jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl\n",
      "Collecting requests (from jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl\n",
      "Collecting ipython (from jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/23/6a/210816c943c9aeeb29e4e18a298f14bf0e118fe222a23e13bfcc2d41b0a4/ipython-7.16.1-py3-none-any.whl\n",
      "Collecting ansi2html (from jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==0.23.1->-r requirements.txt (line 18))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting patsy>=0.4.0 (from statsmodels==0.10.1->-r requirements.txt (line 21))\n",
      "  Using cached https://files.pythonhosted.org/packages/ea/0c/5f61f1a3d4385d6bf83b83ea495068857ff8dfb89e74824c6e9eb63286d8/patsy-0.5.1-py2.py3-none-any.whl\n",
      "Collecting Jinja2>=2.10.1 (from Flask>=1.0.2->dash==1.9.0->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/30/9e/f663a2aa66a09d838042ae1a2c5659828bb9b41ea3a6efa20a20fd92b121/Jinja2-2.11.2-py2.py3-none-any.whl\n",
      "Collecting Werkzeug>=0.15 (from Flask>=1.0.2->dash==1.9.0->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting itsdangerous>=0.24 (from Flask>=1.0.2->dash==1.9.0->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting click>=5.1 (from Flask>=1.0.2->dash==1.9.0->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n",
      "Collecting brotli (from flask-compress->dash==1.9.0->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/d3/7c98f05b7b9103e2f3a112ba42f269c798155b3e5404fb80bb8f823aaebe/Brotli-1.0.9-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting multiprocess>=0.70.10 (from pathos>=0.2.1->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "Collecting ppft>=1.6.6.2 (from pathos>=0.2.1->EMD-signal==0.2.10->-r requirements.txt (line 8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dill>=0.3.2 (from pathos>=0.2.1->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "Collecting pox>=0.2.8 (from pathos>=0.2.1->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "Collecting sphinx>=1.6.5 (from numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/63/b8/34ba32a94cb2b223b941e43b3bcab11281763b95daa8587879eec1eb9a62/Sphinx-3.2.1-py3-none-any.whl\n",
      "Collecting traitlets>=4.1.0 (from ipykernel->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/ca/ab/872a23e29cec3cf2594af7e857f18b687ad21039c1f9b922fac5b9b142d5/traitlets-4.3.3-py2.py3-none-any.whl\n",
      "Collecting tornado>=4.2 (from ipykernel->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "Collecting jupyter-client (from ipykernel->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/dc/41/9fa443d5ae8907dd8f7d12146cb0092dc053afd67b5b57e7e8786a328547/jupyter_client-6.1.7-py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2 (from requests->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5 (from requests->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 (from ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/2b/c1/53ac685833200eb77ef485c2220dac5bfc255418e660790a9eb5cf3abf25/prompt_toolkit-3.0.7-py3-none-any.whl\n",
      "Collecting pexpect; sys_platform != \"win32\" (from ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/39/7b/88dbb785881c28a102619d46423cb853b46dbccc70d3ac362d99773a78ce/pexpect-4.8.0-py2.py3-none-any.whl\n",
      "Collecting jedi>=0.10 (from ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/d4/36136b18daae06ad798966735f6c3fb96869c1be9f8245d2a8f556e40c36/jedi-0.17.2-py2.py3-none-any.whl\n",
      "Collecting pygments (from ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/68/106af3ae51daf807e9cdcba6a90e518954eb8b70341cee52995540a53ead/Pygments-2.6.1-py3-none-any.whl\n",
      "Collecting backcall (from ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/4c/1c/ff6546b6c12603d8dd1070aa3c3d273ad4c07f5771689a7b69a550e8c951/backcall-0.2.0-py2.py3-none-any.whl\n",
      "Collecting setuptools>=18.5 (from ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Downloading https://files.pythonhosted.org/packages/44/a6/7fb6e8b3f4a6051e72e4e2218889351f0ee484b9ee17e995f5ccff780300/setuptools-50.3.0-py3-none-any.whl (785kB)\n",
      "\u001b[K    100% |████████████████████████████████| 788kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting decorator (from ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl\n",
      "Collecting pickleshare (from ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl\n",
      "Collecting MarkupSafe>=0.23 (from Jinja2>=2.10.1->Flask>=1.0.2->dash==1.9.0->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting sphinxcontrib-serializinghtml (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/9a/ca/bfad79b79b3821d0c6361c431f0ef4aec16ee248338b2c2013008b34d345/sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl\n",
      "Collecting sphinxcontrib-htmlhelp (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/36/62/8222554b29b3acde8420128d6d3999c5904d40922ef4b6ccb370e2be7421/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl\n",
      "Collecting sphinxcontrib-applehelp (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/dc/47/86022665a9433d89a66f5911b558ddff69861766807ba685de2e324bd6ed/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl\n",
      "Collecting sphinxcontrib-devhelp (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/09/5de5ed43a521387f18bdf5f5af31d099605c992fd25372b2b9b825ce48ee/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl\n",
      "Collecting packaging (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/46/19/c5ab91b1b05cfe63cccd5cfc971db9214c6dd6ced54e33c30d5af1d2bc43/packaging-20.4-py2.py3-none-any.whl\n",
      "Collecting alabaster<0.8,>=0.7 (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/10/ad/00b090d23a222943eb0eda509720a404f531a439e803f6538f35136cae9e/alabaster-0.7.12-py2.py3-none-any.whl\n",
      "Collecting snowballstemmer>=1.1 (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/7d/4b/cdf1113a0e88b641893b814e9c36f69a6fda28cd88b62c7f0d858cde3166/snowballstemmer-2.0.0-py2.py3-none-any.whl\n",
      "Collecting imagesize (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/31/b2/b5522a0c8d11e4aff83f8342f3f0dea68c2fb25aa44403e420587f0ce204/imagesize-1.2.0-py2.py3-none-any.whl\n",
      "Collecting sphinxcontrib-qthelp (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/2b/14/05f9206cf4e9cfca1afb5fd224c7cd434dcc3a433d6d9e4e0264d29c6cdb/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl\n",
      "Collecting sphinxcontrib-jsmath (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/42/4c8646762ee83602e3fb3fbe774c2fac12f317deb0b5dbeeedd2d3ba4b77/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\n",
      "Collecting docutils>=0.12 (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/81/44/8a15e45ffa96e6cf82956dd8d7af9e666357e16b0d93b253903475ee947f/docutils-0.16-py2.py3-none-any.whl\n",
      "Collecting babel>=1.3 (from sphinx>=1.6.5->numpydoc->EMD-signal==0.2.10->-r requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/15/a1/522dccd23e5d2e47aed4b6a16795b8213e3272c7506e625f2425ad025a19/Babel-2.8.0-py2.py3-none-any.whl\n",
      "Collecting ipython-genutils (from traitlets>=4.1.0->ipykernel->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl\n",
      "Collecting jupyter-core>=4.6.0 (from jupyter-client->ipykernel->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/63/0d/df2d17cdf389cea83e2efa9a4d32f7d527ba78667e0153a8e676e957b2f7/jupyter_core-4.6.3-py2.py3-none-any.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyzmq>=13 (from jupyter-client->ipykernel->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/56/ff/34bf45e5cf8367edcf4946b26690f0982b3ec701b0a655edfe562d29e246/pyzmq-19.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting wcwidth (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/59/7c/e39aca596badaf1b78e8f547c807b04dae603a433d3e7a7e04d67f2ef3e5/wcwidth-0.2.5-py2.py3-none-any.whl\n",
      "Collecting ptyprocess>=0.5 (from pexpect; sys_platform != \"win32\"->ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/29/605c2cc68a9992d18dada28206eeada56ea4bd07a239669da41674648b6f/ptyprocess-0.6.0-py2.py3-none-any.whl\n",
      "Collecting parso<0.8.0,>=0.7.0 (from jedi>=0.10->ipython->jupyter-dash==0.3.1->-r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/93/d1/e635bdde32890db5aeb2ffbde17e74f68986305a4466b0aa373b861e3f00/parso-0.7.1-py2.py3-none-any.whl\n",
      "Installing collected packages: MarkupSafe, Jinja2, Werkzeug, itsdangerous, click, Flask, dash-renderer, future, brotli, flask-compress, six, retrying, plotly, dash-core-components, dash-table, dash-html-components, dash, dash-bootstrap-components, dash-daq, dill, multiprocess, ppft, pox, pathos, sphinxcontrib-serializinghtml, sphinxcontrib-htmlhelp, sphinxcontrib-applehelp, pygments, chardet, idna, certifi, urllib3, requests, sphinxcontrib-devhelp, pyparsing, packaging, alabaster, snowballstemmer, imagesize, sphinxcontrib-qthelp, sphinxcontrib-jsmath, docutils, pytz, babel, setuptools, sphinx, numpydoc, numpy, scipy, EMD-signal, fastdtw, joblib, python-dateutil, cycler, kiwisolver, matplotlib, pandas, seaborn, missingno, PyYAML, wcwidth, prompt-toolkit, ptyprocess, pexpect, parso, jedi, backcall, decorator, pickleshare, ipython-genutils, traitlets, ipython, tornado, jupyter-core, pyzmq, jupyter-client, ipykernel, ansi2html, jupyter-dash, threadpoolctl, scikit-learn, patsy, statsmodels\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/commands/install.py\", line 360, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_set.py\", line 784, in install\n",
      "    **kwargs\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_install.py\", line 851, in install\n",
      "    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_install.py\", line 1064, in move_wheel_files\n",
      "    isolated=self.isolated,\n",
      "  File \"/usr/lib/python3/dist-packages/pip/wheel.py\", line 247, in move_wheel_files\n",
      "    prefix=prefix,\n",
      "  File \"/usr/lib/python3/dist-packages/pip/locations.py\", line 153, in distutils_scheme\n",
      "    i.finalize_options()\n",
      "  File \"/usr/lib/python3.6/distutils/command/install.py\", line 351, in finalize_options\n",
      "    self.create_home_path()\n",
      "  File \"/usr/lib/python3.6/distutils/command/install.py\", line 581, in create_home_path\n",
      "    os.makedirs(path, 0o700)\n",
      "  File \"/usr/lib/python3.6/os.py\", line 210, in makedirs\n",
      "    makedirs(head, mode, exist_ok)\n",
      "  File \"/usr/lib/python3.6/os.py\", line 220, in makedirs\n",
      "    mkdir(name, mode)\n",
      "PermissionError: [Errno 13] Permission denied: '/home/skhosh/.local/lib/python3.6'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import base64\n",
    "import clusterlib\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_table\n",
    "import datetime\n",
    "import functions\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np    \n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as hac\n",
    "import seaborn as sns\n",
    "import re\n",
    "import styles\n",
    "import sys\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from dash.dependencies import Output, Input, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "from datetime import datetime, timedelta\n",
    "from dt_help import Helper\n",
    "from dt_read import DataProcessor\n",
    "from jupyter_dash import JupyterDash\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import cophenet, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from plotly.figure_factory import create_2d_density\n",
    "\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None \n",
    "register_matplotlib_converters()\n",
    "\n",
    "####################################################################################################################################################################################\n",
    "#                                                                                            raw data                                                                              # \n",
    "####################################################################################################################################################################################\n",
    "    \n",
    "df_hk_daily, df_nikkei_daily, df_spmini500_daily, df_eustoxx50_daily, df_vix_daily, \\\n",
    "df_hk_minute, df_nikkei_minute, df_spmini500_minute, df_eustoxx50_minute, df_vix_minute, \\\n",
    "hk_daily_dates,nikkei_daily_dates,spmini_daily_dates,eu_daily_dates,vix_daily_dates, \\\n",
    "hk_minute_dates,nikkei_minute_dates,spmini_minute_dates,eu_minute_dates,vix_minute_dates = functions.get_data_all()\n",
    "\n",
    "cut_cluster, cut_cluster_num, max_cluster_rep = functions.get_conf_helper()\n",
    "options_max_cluster = [{'label': i, 'value': i} for i in range(int(max_cluster_rep))]\n",
    "\n",
    "def get_df_choice(freq,index_val,wnd):\n",
    "    if(freq == 'daily' and index_val=='HangSeng'):\n",
    "        df = df_hk_daily\n",
    "    elif(freq == 'daily' and index_val == 'Nikkei225'):\n",
    "        df = df_nikkei_daily\n",
    "    elif(freq == 'daily' and index_val == 'eMiniSP500'):\n",
    "        df = df_spmini500_daily\n",
    "    elif(freq == 'daily' and index_val == 'EuroStoxx50'):\n",
    "        df = df_eustoxx50_daily\n",
    "    elif(freq == 'daily' and index_val == 'VIX'):\n",
    "        df = df_vix_daily\n",
    "    elif(freq == '15min' and index_val == 'HangSeng'):\n",
    "        df = df_hk_minute\n",
    "    elif(freq == '15min' and index_val == 'Nikkei225'):\n",
    "        df = df_nikkei_minute\n",
    "    elif(freq == '15min' and index_val == 'eMiniSP500'):\n",
    "        df = df_spmini500_minute\n",
    "    elif(freq == '15min' and index_val == 'EuroStoxx50'):\n",
    "        df = df_eustoxx50_minute\n",
    "    elif(freq == '15min' and index_val == 'VIX'):\n",
    "        df = df_vix_minute\n",
    "    return(df)\n",
    "\n",
    "def all_common_dates():\n",
    "    start_date_minute = pd.to_datetime('2020-01-06 00:00:00').tz_localize('UTC')\n",
    "    end_date_minute = pd.to_datetime('2020-06-01 23:59:59').tz_localize('UTC')\n",
    "   \n",
    "    # find daily dates that are common to all indices (filtering out holdidays included in one market but not the other for example)\n",
    "    start_date_daily = pd.to_datetime('2020-'\"{:02d}\"'-'\"{:02d}\".format(start_date_minute.month,start_date_minute.day))\n",
    "    end_date_daily = pd.to_datetime('2020-'\"{:02d}\"'-'\"{:02d}\".format(end_date_minute.month,end_date_minute.day))\n",
    "\n",
    "    days_hk = pd.DataFrame(hk_daily_dates[hk_daily_dates >= start_date_daily])\n",
    "    days_nk = pd.DataFrame(nikkei_daily_dates[nikkei_daily_dates >= start_date_daily])\n",
    "    days_sp = pd.DataFrame(spmini_daily_dates[spmini_daily_dates >= start_date_daily])\n",
    "    days_eu = pd.DataFrame(eu_daily_dates[eu_daily_dates >= start_date_daily])\n",
    "\n",
    "    tmp_hk = [ pd.to_datetime(el) for el in days_hk['Dates'].values ]\n",
    "    tmp_nk = [ pd.to_datetime(el) for el in days_nk['Dates'].values ]\n",
    "    tmp_sp = [ pd.to_datetime(el) for el in days_sp['Dates'].values ]\n",
    "    tmp_eu = [ pd.to_datetime(el) for el in days_eu['Dates'].values ]\n",
    "\n",
    "    days_hk_filter = [ \"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day) for el in tmp_hk ]\n",
    "    days_nk_filter = [ \"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day) for el in tmp_nk ]\n",
    "    days_sp_filter = [ \"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day) for el in tmp_sp ]\n",
    "    days_eu_filter = [ \"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day) for el in tmp_eu ]\n",
    "    \n",
    "    elements_in_all = list(set.intersection(*map(set, [days_hk_filter,days_nk_filter,days_sp_filter,days_eu_filter])))\n",
    "\n",
    "    days_all = sorted(elements_in_all, key=lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "    days_all = [pd.to_datetime(el) for el in days_all]\n",
    "    return(days_all)\n",
    "\n",
    "#####################################################################################################################################################################################\n",
    "    \n",
    "def table_stats_ohlc(df_hk,df_nk,df_sp,df_eu,ohlc):\n",
    "    days_all = all_common_dates()\n",
    "    \n",
    "    # for each daily date take a full 24hr session (for all indices)\n",
    "    stats_all = []\n",
    "    for el in days_all:\n",
    "        sd = pd.to_datetime(str(el.date()) + ' 00:00:00').tz_localize('UTC')\n",
    "        ed = pd.to_datetime(str(el.date()) + ' 23:59:59').tz_localize('UTC')\n",
    "        \n",
    "        mask_hk = (df_hk.index >= sd) & (df_hk.index <= ed)\n",
    "        mask_nk = (df_nk.index >= sd) & (df_nk.index <= ed)\n",
    "        mask_sp = (df_sp.index >= sd) & (df_sp.index <= ed)\n",
    "        mask_eu = (df_eu.index >= sd) & (df_eu.index <= ed)\n",
    "\n",
    "        df_hk_select = df_hk.loc[mask_hk]\n",
    "        df_nk_select = df_nk.loc[mask_nk]\n",
    "        df_sp_select = df_sp.loc[mask_sp]\n",
    "        df_eu_select = df_eu.loc[mask_eu]\n",
    "\n",
    "        stats_all.append(functions.stats_ohlc(df_hk_select,df_nk_select,df_sp_select,df_eu_select,el,ohlc))\n",
    "\n",
    "    df_all = pd.concat(stats_all,axis=0,ignore_index=True)\n",
    "    return(df_all)\n",
    "\n",
    "#####################################################################################################################################################################################\n",
    "    \n",
    "def get_all_first_last(df_hk,df_nk,df_sp,df_eu,ohlc,hours_diff):\n",
    "    days_all = all_common_dates()\n",
    "\n",
    "    df_all_last_hang = pd.DataFrame(index=range(len(days_all)),columns=['Dates','growth'])\n",
    "    df_all_last_nikkei = pd.DataFrame(index=range(len(days_all)),columns=['Dates','growth'])\n",
    "    df_all_last_spmini500 = pd.DataFrame(index=range(len(days_all)),columns=['Dates','growth'])\n",
    "    df_all_last_eustoxx50 = pd.DataFrame(index=range(len(days_all)),columns=['Dates','growth'])\n",
    "\n",
    "    df_all_first_hang = pd.DataFrame(index=range(len(days_all)),columns=['Dates','growth'])\n",
    "    df_all_first_nikkei = pd.DataFrame(index=range(len(days_all)),columns=['Dates','growth'])\n",
    "    df_all_first_spmini500 = pd.DataFrame(index=range(len(days_all)),columns=['Dates','growth'])\n",
    "    df_all_first_eustoxx50 = pd.DataFrame(index=range(len(days_all)),columns=['Dates','growth'])\n",
    "    \n",
    "    # for each daily date take a full 24hr session (for all indices)\n",
    "    for i,el in enumerate(days_all):\n",
    "        sd_hang = pd.to_datetime(str(el.date()) + ' 01:45:00').tz_localize('UTC')\n",
    "        ed_hang = pd.to_datetime(str(el.date()) + ' 08:00:00').tz_localize('UTC')\n",
    "\n",
    "        sd_nikkei = pd.to_datetime(str(el.date()) + ' 00:00:00').tz_localize('UTC')\n",
    "        ed_nikkei = pd.to_datetime(str(el.date()) + ' 06:00:00').tz_localize('UTC')\n",
    "\n",
    "        sd_spmini500 = pd.to_datetime(str(el.date()) + ' 13:30:00').tz_localize('UTC')\n",
    "        ed_spmini500 = pd.to_datetime(str(el.date()) + ' 20:00:00').tz_localize('UTC')\n",
    "\n",
    "        sd_eustoxx50 = pd.to_datetime(str(el.date()) + ' 07:00:00').tz_localize('UTC')\n",
    "        ed_eustoxx50 = pd.to_datetime(str(el.date()) + ' 15:30:00').tz_localize('UTC')\n",
    "        \n",
    "        mask_hang = (df_hk.index >= sd_hang) & (df_hk.index <= ed_hang)\n",
    "        mask_nikkei = (df_nk.index >= sd_nikkei) & (df_nk.index <= ed_nikkei)\n",
    "        mask_spmini500 = (df_sp.index >= sd_spmini500) & (df_sp.index <= ed_spmini500)\n",
    "        mask_eustoxx50 = (df_eu.index >= sd_eustoxx50) & (df_eu.index <= ed_eustoxx50)\n",
    "\n",
    "        df_hang_select = df_hk.loc[mask_hang]\n",
    "        df_nikkei_select = df_nk.loc[mask_nikkei]\n",
    "        df_spmini500_select = df_sp.loc[mask_spmini500]\n",
    "        df_eustoxx50_select = df_eu.loc[mask_eustoxx50]\n",
    "\n",
    "        df_hang_select['rate_ret'] = df_hang_select[ohlc].pct_change().dropna()\n",
    "        df_nikkei_select['rate_ret'] = df_nikkei_select[ohlc].pct_change().dropna()       \n",
    "        df_spmini500_select['rate_ret'] = df_spmini500_select[ohlc].pct_change().dropna()       \n",
    "        df_eustoxx50_select['rate_ret'] = df_eustoxx50_select[ohlc].pct_change().dropna()\n",
    "        \n",
    "        # get the last 'hours_diff' hours\n",
    "        mask_hang_last = (df_hang_select.index >= df_hang_select.index[-1]-timedelta(hours=hours_diff, minutes=00, seconds=00))\n",
    "        mask_nikkei_last = (df_nikkei_select.index >= df_nikkei_select.index[-1]-timedelta(hours=hours_diff, minutes=00, seconds=00))\n",
    "        mask_spmini500_last = (df_spmini500_select.index >= df_spmini500_select.index[-1]-timedelta(hours=hours_diff, minutes=00, seconds=00))\n",
    "        mask_eustoxx50_last = (df_eustoxx50_select.index >= df_eustoxx50_select.index[-1]-timedelta(hours=hours_diff, minutes=00, seconds=00))\n",
    "\n",
    "        df_hang_select_last = df_hang_select.loc[mask_hang_last]\n",
    "        df_nikkei_select_last = df_nikkei_select.loc[mask_nikkei_last]\n",
    "        df_spmini500_select_last = df_spmini500_select.loc[mask_spmini500_last]\n",
    "        df_eustoxx50_select_last = df_eustoxx50_select.loc[mask_eustoxx50_last]\n",
    "\n",
    "        # get cumulative returns of the last 'hours_diff' hours\n",
    "        df_hang_select_last['growth'] = (1.0+df_hang_select_last['rate_ret']).cumprod()\n",
    "        df_hang_select_last['growth'].iloc[0] = 1\n",
    "        res_hang_1 = df_hang_select_last[[el for el in df_hang_select_last.columns if 'growth' in el]].iloc[-1].values[0]\n",
    "        res_hang_2 = df_hang_select_last[[el for el in df_hang_select_last.columns if 'growth' in el]].iloc[0].values[0]\n",
    "        growth_hang = res_hang_1/res_hang_2 - 1.0\n",
    "        \n",
    "        df_nikkei_select_last['growth'] = (1.0+df_nikkei_select_last['rate_ret']).cumprod()\n",
    "        df_nikkei_select_last['growth'].iloc[0] = 1\n",
    "        res_nikkei_1 = df_nikkei_select_last[[el for el in df_nikkei_select_last.columns if 'growth' in el]].iloc[-1].values[0]\n",
    "        res_nikkei_2 = df_nikkei_select_last[[el for el in df_nikkei_select_last.columns if 'growth' in el]].iloc[0].values[0]\n",
    "        growth_nikkei = res_nikkei_1/res_nikkei_2 - 1.0\n",
    "\n",
    "        df_spmini500_select_last['growth'] = (1.0+df_spmini500_select_last['rate_ret']).cumprod()\n",
    "        df_spmini500_select_last['growth'].iloc[0] = 1\n",
    "        res_spmini500_1 = df_spmini500_select_last[[el for el in df_spmini500_select_last.columns if 'growth' in el]].iloc[-1].values[0]\n",
    "        res_spmini500_2 = df_spmini500_select_last[[el for el in df_spmini500_select_last.columns if 'growth' in el]].iloc[0].values[0]\n",
    "        growth_spmini500 = res_spmini500_1/res_spmini500_2 - 1.0\n",
    "\n",
    "        df_eustoxx50_select_last['growth'] = (1.0+df_eustoxx50_select_last['rate_ret']).cumprod()\n",
    "        df_eustoxx50_select_last['growth'].iloc[0] = 1\n",
    "        res_eustoxx50_1 = df_eustoxx50_select_last[[el for el in df_eustoxx50_select_last.columns if 'growth' in el]].iloc[-1].values[0]\n",
    "        res_eustoxx50_2 = df_eustoxx50_select_last[[el for el in df_eustoxx50_select_last.columns if 'growth' in el]].iloc[0].values[0]\n",
    "        growth_eustoxx50 = res_eustoxx50_1/res_eustoxx50_2 - 1.0\n",
    "\n",
    "        df_all_last_hang.iloc[i] = [\"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day),growth_hang]\n",
    "        df_all_last_nikkei.iloc[i] = [\"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day),growth_nikkei]\n",
    "        df_all_last_spmini500.iloc[i] = [\"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day),growth_spmini500]\n",
    "        df_all_last_eustoxx50.iloc[i] = [\"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day),growth_eustoxx50]\n",
    "\n",
    "        # get the first 'hours_diff' hours\n",
    "        mask_hang_first = (df_hang_select.index <= df_hang_select.index[0]+timedelta(hours=hours_diff, minutes=00, seconds=00))\n",
    "        mask_nikkei_first = (df_nikkei_select.index <= df_nikkei_select.index[0]+timedelta(hours=hours_diff, minutes=00, seconds=00))\n",
    "        mask_spmini500_first = (df_spmini500_select.index <= df_spmini500_select.index[0]+timedelta(hours=hours_diff, minutes=00, seconds=00))\n",
    "        mask_eustoxx50_first = (df_eustoxx50_select.index <= df_eustoxx50_select.index[0]+timedelta(hours=hours_diff, minutes=00, seconds=00))\n",
    "\n",
    "        df_hang_select_first = df_hang_select.loc[mask_hang_first]\n",
    "        df_nikkei_select_first = df_nikkei_select.loc[mask_nikkei_first]\n",
    "        df_spmini500_select_first = df_spmini500_select.loc[mask_spmini500_first]\n",
    "        df_eustoxx50_select_first = df_eustoxx50_select.loc[mask_eustoxx50_first]\n",
    "\n",
    "        # get cumulative returns of the first 'hours_diff' hours\n",
    "        df_hang_select_first['growth'] = (1.0+df_hang_select_first['rate_ret']).cumprod()\n",
    "        df_hang_select_first['growth'].iloc[0] = 1\n",
    "        res_hang_1 = df_hang_select_first[[el for el in df_hang_select_first.columns if 'growth' in el]].iloc[-1].values[0]\n",
    "        res_hang_2 = df_hang_select_first[[el for el in df_hang_select_first.columns if 'growth' in el]].iloc[0].values[0]\n",
    "        growth_hang = res_hang_1/res_hang_2 - 1.0\n",
    "        \n",
    "        df_nikkei_select_first['growth'] = (1.0+df_nikkei_select_first['rate_ret']).cumprod()\n",
    "        df_nikkei_select_first['growth'].iloc[0] = 1\n",
    "        res_nikkei_1 = df_nikkei_select_first[[el for el in df_nikkei_select_first.columns if 'growth' in el]].iloc[-1].values[0]\n",
    "        res_nikkei_2 = df_nikkei_select_first[[el for el in df_nikkei_select_first.columns if 'growth' in el]].iloc[0].values[0]\n",
    "        growth_nikkei = res_nikkei_1/res_nikkei_2 - 1.0\n",
    "\n",
    "        df_spmini500_select_first['growth'] = (1.0+df_spmini500_select_first['rate_ret']).cumprod()\n",
    "        df_spmini500_select_first['growth'].iloc[0] = 1\n",
    "        res_spmini500_1 = df_spmini500_select_first[[el for el in df_spmini500_select_first.columns if 'growth' in el]].iloc[-1].values[0]\n",
    "        res_spmini500_2 = df_spmini500_select_first[[el for el in df_spmini500_select_first.columns if 'growth' in el]].iloc[0].values[0]\n",
    "        growth_spmini500 = res_spmini500_1/res_spmini500_2 - 1.0\n",
    "\n",
    "        df_eustoxx50_select_first['growth'] = (1.0+df_eustoxx50_select_first['rate_ret']).cumprod()\n",
    "        df_eustoxx50_select_first['growth'].iloc[0] = 1\n",
    "        res_eustoxx50_1 = df_eustoxx50_select_first[[el for el in df_eustoxx50_select_first.columns if 'growth' in el]].iloc[-1].values[0]\n",
    "        res_eustoxx50_2 = df_eustoxx50_select_first[[el for el in df_eustoxx50_select_first.columns if 'growth' in el]].iloc[0].values[0]\n",
    "        growth_eustoxx50 = res_eustoxx50_1/res_eustoxx50_2 - 1.0\n",
    "\n",
    "        df_all_first_hang.iloc[i] = [\"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day),growth_hang]\n",
    "        df_all_first_nikkei.iloc[i] = [\"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day),growth_nikkei]\n",
    "        df_all_first_spmini500.iloc[i] = [\"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day),growth_spmini500]\n",
    "        df_all_first_eustoxx50.iloc[i] = [\"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day),growth_eustoxx50]\n",
    "    \n",
    "    df_all_last_hang.set_index('Dates',inplace=True)\n",
    "    df_all_last_nikkei.set_index('Dates',inplace=True)\n",
    "    df_all_last_spmini500.set_index('Dates',inplace=True)\n",
    "    df_all_last_eustoxx50.set_index('Dates',inplace=True)\n",
    "\n",
    "    df_all_first_hang.set_index('Dates',inplace=True)\n",
    "    df_all_first_nikkei.set_index('Dates',inplace=True)\n",
    "    df_all_first_spmini500.set_index('Dates',inplace=True)\n",
    "    df_all_first_eustoxx50.set_index('Dates',inplace=True)\n",
    "\n",
    "    return(df_all_last_hang,df_all_last_nikkei,df_all_last_spmini500,df_all_last_eustoxx50,\n",
    "           df_all_first_hang,df_all_first_nikkei,df_all_first_spmini500,df_all_first_eustoxx50)\n",
    "\n",
    "\n",
    "def stats_dataframes(ohlc,days_all):\n",
    "    df_hang_select_all = []\n",
    "    df_nikkei_select_all = []\n",
    "    df_spmini500_select_all = []\n",
    "    df_eustoxx50_select_all = []\n",
    "    \n",
    "    # for each daily date take a full 24hr session (for all indices)\n",
    "    for i,el in enumerate(days_all):\n",
    "        sd = pd.to_datetime(str(el.date()) + ' 00:00:00').tz_localize('UTC')\n",
    "        ed = pd.to_datetime(str(el.date()) + ' 23:59:59').tz_localize('UTC')\n",
    "        \n",
    "        mask_hang = (df_hk_minute.index >= sd) & (df_hk_minute.index <= ed)\n",
    "        mask_nikkei = (df_nikkei_minute.index >= sd) & (df_nikkei_minute.index <= ed)\n",
    "        mask_spmini500 = (df_spmini500_minute.index >= sd) & (df_spmini500_minute.index <= ed)\n",
    "        mask_eustoxx50 = (df_eustoxx50_minute.index >= sd) & (df_eustoxx50_minute.index <= ed)\n",
    "\n",
    "        df_hang_select = df_hk_minute.loc[mask_hang]\n",
    "        df_nikkei_select = df_nikkei_minute.loc[mask_nikkei]\n",
    "        df_spmini500_select = df_spmini500_minute.loc[mask_spmini500]\n",
    "        df_eustoxx50_select = df_eustoxx50_minute.loc[mask_eustoxx50]\n",
    "\n",
    "        df_hang_select['rate_ret'] = df_hang_select[ohlc].pct_change()\n",
    "        df_nikkei_select['rate_ret'] = df_nikkei_select[ohlc].pct_change()\n",
    "        df_spmini500_select['rate_ret'] = df_spmini500_select[ohlc].pct_change()\n",
    "        df_eustoxx50_select['rate_ret'] = df_eustoxx50_select[ohlc].pct_change()\n",
    "\n",
    "        df_hang_select.dropna(inplace=True)\n",
    "        df_nikkei_select.dropna(inplace=True)\n",
    "        df_spmini500_select.dropna(inplace=True)\n",
    "        df_eustoxx50_select.dropna(inplace=True)\n",
    "\n",
    "        df_hang_select_all.append(df_hang_select['rate_ret'].T)\n",
    "        df_nikkei_select_all.append(df_nikkei_select['rate_ret'].T)\n",
    "        df_spmini500_select_all.append(df_spmini500_select['rate_ret'].T)\n",
    "        df_eustoxx50_select_all.append(df_eustoxx50_select['rate_ret'].T)\n",
    "        \n",
    "    return(df_hang_select_all,df_nikkei_select_all,df_spmini500_select_all,df_eustoxx50_select_all)\n",
    "\n",
    "def stats_dataframes_ohlc(ohlc,days_all):\n",
    "    df_hang_select_all = []\n",
    "    df_nikkei_select_all = []\n",
    "    df_spmini500_select_all = []\n",
    "    df_eustoxx50_select_all = []\n",
    "    \n",
    "    # for each daily date take a full 24hr session (for all indices)\n",
    "    for i,el in enumerate(days_all):\n",
    "        sd = pd.to_datetime(str(el.date()) + ' 00:00:00').tz_localize('UTC')\n",
    "        ed = pd.to_datetime(str(el.date()) + ' 23:59:59').tz_localize('UTC')\n",
    "        \n",
    "        mask_hang = (df_hk_minute.index >= sd) & (df_hk_minute.index <= ed)\n",
    "        mask_nikkei = (df_nikkei_minute.index >= sd) & (df_nikkei_minute.index <= ed)\n",
    "        mask_spmini500 = (df_spmini500_minute.index >= sd) & (df_spmini500_minute.index <= ed)\n",
    "        mask_eustoxx50 = (df_eustoxx50_minute.index >= sd) & (df_eustoxx50_minute.index <= ed)\n",
    "\n",
    "        df_hang_select = df_hk_minute.loc[mask_hang]\n",
    "        df_nikkei_select = df_nikkei_minute.loc[mask_nikkei]\n",
    "        df_spmini500_select = df_spmini500_minute.loc[mask_spmini500]\n",
    "        df_eustoxx50_select = df_eustoxx50_minute.loc[mask_eustoxx50]\n",
    "\n",
    "        df_hang_select['norm'] = (df_hang_select[ohlc].values - np.mean(df_hang_select[ohlc].values)) / np.max(df_hang_select[ohlc].values)\n",
    "        df_nikkei_select['norm'] = (df_nikkei_select[ohlc].values - np.mean(df_nikkei_select[ohlc].values)) / np.max(df_nikkei_select[ohlc].values)\n",
    "        df_spmini500_select['norm'] = (df_spmini500_select[ohlc].values - np.mean(df_spmini500_select[ohlc].values)) / np.max(df_spmini500_select[ohlc].values)  \n",
    "        df_eustoxx50_select['norm'] = (df_eustoxx50_select[ohlc].values - np.mean(df_eustoxx50_select[ohlc].values)) / np.max(df_eustoxx50_select[ohlc].values) \n",
    "        \n",
    "        df_hang_select_all.append(df_hang_select)\n",
    "        df_nikkei_select_all.append(df_nikkei_select)\n",
    "        df_spmini500_select_all.append(df_spmini500_select)\n",
    "        df_eustoxx50_select_all.append(df_eustoxx50_select)\n",
    "        \n",
    "    return(df_hang_select_all,df_nikkei_select_all,df_spmini500_select_all,df_eustoxx50_select_all)\n",
    "\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        layout_1\n",
    "##########################################################################################################################################################################################\n",
    "def get_layout_1():\n",
    "    html_res = \\\n",
    "    html.Div([\n",
    "              html.Div([\n",
    "                        html.Div(html.P([html.Br(),html.H2(html.B('For each chosen index, different metrics are shown. The moving average represented in the graph is based on the Close value. It is also possible to show for different backward windows. We notice that the most active sessions start from March and span along this month')),html.Br(),html.H2(html.B('For Nikkei, the daily trend in terms of volume activity shows, during each cycle, the same pattern: a peak and gradual decrease')),html.Br(),html.H2(html.B('For Hang Seng, the daily trend in terms of volume activity shows a parabolic evolution during each cycle')),html.Br(),html.H2(html.B('For SP500, the daily trend in terms of volume activity shows a net uniform trend during half of a 24hr cycle and lesser activity during the other half and is similar for EuroStoxx50'))]), style=styles.STYLE_8),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H4('Frequency'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ohlc-dd-freq',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['daily','15min']],\n",
    "                                      value='15min',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_9),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H4('Index choice'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ohlc-dd-index',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['Nikkei225','HangSeng','eMiniSP500','EuroStoxx50','VIX']],\n",
    "                                      value='Nikkei225',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_9),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H4('Moving average time window'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ohlc-dd-mvavg',\n",
    "                                      options=[{'label': str(i//60)+'hr', 'value': str(i)+'T'} for i in [60,120,240,720,1440]],\n",
    "                                      value='60T',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_9),\n",
    "                        html.Div([\n",
    "                                  dcc.Graph(\n",
    "                                      id = 'ohlc',\n",
    "                                      style=styles.STYLE_4)\n",
    "                                      ])\n",
    "                                      ])\n",
    "              ])\n",
    "    return(html_res)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        layout_2\n",
    "##########################################################################################################################################################################################\n",
    "def get_layout_2():\n",
    "    html_res = \\\n",
    "    html.Div([\n",
    "              html.Div([\n",
    "                        html.Div(html.P([html.Br(),html.H2(html.B('Now we look at the corrleation between the OHLCV componenent of each index. These price components (OHLC) are then selected based on the chosen correlation threshold'))]), style=styles.STYLE_8)]),\n",
    "              html.Div([\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('Frequency'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='htpp-dd-freq',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['daily','15min']],\n",
    "                                      value='daily',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_3),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('threshold correlation'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='htpp-dd-thrs',\n",
    "                                      options=[{'label': i, 'value': i} for i in [round(el,2) for el in np.linspace(-1.0,1.0,21)]],\n",
    "                                      value=0.9,\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_3),\n",
    "                        html.Div([\n",
    "                                  dcc.Graph(\n",
    "                                      id = 'corr',\n",
    "                                      style=styles.STYLE_4)\n",
    "                                      ]),\n",
    "                        html.Div([\n",
    "                                  html.Div(\n",
    "                                      id='corr-table',\n",
    "                                      className='tableDiv'\n",
    "                                      )\n",
    "                                  ],style=styles.STYLE_4),\n",
    "                        ]),\n",
    "              ])\n",
    "    return(html_res)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        layout_3\n",
    "##########################################################################################################################################################################################  \n",
    "def get_layout_3():\n",
    "    html_res = \\\n",
    "    html.Div([\n",
    "              html.Div([\n",
    "                        html.Div(html.P([html.Br(),html.H2(html.B('For each index, a date can be chosen for which the distributions for the 15 minute data are computed both for the relative return and the logarithmic return.')),html.Br(),html.H2(html.B('Once a choice is made on Index 1 and Index 2, then a corresponding day and month have to be chosen (relative to each index). For each of the dates selected a daily trading session session is uploaded and the returns for these are plotted vs each other to check on the relationship. This allows to select pairs from the Correlation page (selection made on their correlation threshold).'))]), style=styles.STYLE_8)\n",
    "                        ]),\n",
    "              html.Div([\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('Index Choice - 1'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ret-dd-idx-1',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['Nikkei225','HangSeng','eMiniSP500','EuroStoxx50','VIX']],\n",
    "                                      value='Nikkei225',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_3),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('Index Choice - 2'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ret-dd-idx-2',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['Nikkei225','HangSeng','eMiniSP500','EuroStoxx50','VIX']],\n",
    "                                      value='eMiniSP500',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_3),\n",
    "                     ]),\n",
    "              html.Div([\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('Day - 1'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ret-dd-day-1',\n",
    "                                      options=[{'label': i, 'value': int(i)} for i in range(1,31)],\n",
    "                                      value=5,\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_10),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('Month - 1'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ret-dd-month-1',\n",
    "                                      options=[{'label': i, 'value': int(i)} for i in range(1,7)],\n",
    "                                      value=3,\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_10),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('OHLC Choice - 1'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ret-dd-ohlc-1',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['Open','High','Low','Close']],\n",
    "                                      value='Close',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_10),                        \n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('Day - 2'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ret-dd-day-2',\n",
    "                                      options=[{'label': i, 'value': int(i)} for i in range(1,31)],\n",
    "                                      value=5,\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_10),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('Month - 2'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ret-dd-month-2',\n",
    "                                      options=[{'label': i, 'value': int(i)} for i in range(1,7)],\n",
    "                                      value=3,\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_10),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('OHLC Choice - 2'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='ret-dd-ohlc-2',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['Open','High','Low','Close']],\n",
    "                                      value='Close',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_10),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.P([html.Br(),html.H2(html.B('Simple return between indices at different dates')),html.Br()]), style=styles.STYLE_8),\n",
    "                                  dcc.Graph(\n",
    "                                      id = 'ret-dist-comp',\n",
    "                                      style=styles.STYLE_4\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_3),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.P([html.Br(),html.H2(html.B('Log-return between indices at different dates')),html.Br()]), style=styles.STYLE_8),\n",
    "                                  dcc.Graph(\n",
    "                                      id = 'log-ret-dist-comp',\n",
    "                                      style=styles.STYLE_4\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_3),\n",
    "                         ])\n",
    "              ])\n",
    "    \n",
    "    return(html_res)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        layout_4\n",
    "##########################################################################################################################################################################################  \n",
    "def get_layout_4():\n",
    "    html_res = \\\n",
    "    html.Div([\n",
    "              html.Div([\n",
    "              html.Div([\n",
    "                        html.Div(html.P([html.Br(),html.H2(html.B('First we find all dates that are common to all indices. For each day, a full trading session span is selected. For each daily session and for each market')),html.Br(),html.H2(html.B('day_sess: date of the selected time span')),html.Br(),html.H2(html.B('st_sess: start of the session where the statistics are computed')),html.Br(),html.H2(html.B('ed_sess: end of the session where the statistics are computed')),html.Br(),html.H2(html.B('mdd: Maximum Drawdon during the daily session (expressed in %)')),html.Br(),html.H2(html.B('Volatility during the daily session (expressed in %)')),html.Br(),html.H2(html.B('growth: growth of the portfolio (computed as end/start value from the cumulative return -> cumprod(1+return)')),html.Br(),html.H2(html.B('max_ret_time: corresponds to the first time the maximum is reached')),html.Br(),html.H2(html.B('min_ret_time: corresponds to the first time the minimum is reached')),html.Br(),html.H2(html.B('mean_return during the daily session (expressed in %)')),html.Br(),html.H2(html.B('pos_return: shows if session returned positive or negative')),html.Br(),html.H2(html.B('up_ratio: number of up moves / total moves (in returns term, expressed in % of total moves)')),html.Br(),html.H2(html.B('down_ratio: number of down moves / total moves (in returns term, expressed in % of total moves)')),html.Br(),html.H2(html.B('index_market: name of the index')),html.Br(),html.H2(html.B('The table below gives all the statistics relative to returns and can be recalculated for each of the OHLC parameters. The table is also filterable/selectable/deletable and sortable')),html.Br(),html.H2(html.B('In the filter line expression such as \">value\" can be written to filter out by specific range. Filter queries can be entered in the pop windows and then are automatically translated into full queries which can then be reused.'))]), style=styles.STYLE_8)\n",
    "                        ]),\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('OHLC Choice'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='stats-dd-ohlc',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['Open','High','Low','Close']],\n",
    "                                      value='Close',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_3),\n",
    "                        html.Div([\n",
    "                            html.Div(html.P([html.Br(),html.H5(html.B('')),html.Br(),html.H5(html.B(''))]), style=styles.STYLE_8)\n",
    "                            ]),\n",
    "                        html.Div([\n",
    "                                  dcc.RadioItems(\n",
    "                                      id='filter-query-read-write-stats',\n",
    "                                      options=[\n",
    "                                               {'label': 'Read filter_query', 'value': 'read'},\n",
    "                                               {'label': 'Write to filter_query', 'value': 'write'}\n",
    "                                               ],\n",
    "                                      value='read'\n",
    "                                      ),\n",
    "                                  html.Br(),\n",
    "                                  dcc.Input(id='filter-query-input-stats', placeholder='Enter filter query'),\n",
    "                                  html.Div(id='filter-query-output-stats'),\n",
    "                                  html.Hr()\n",
    "                        ]),\n",
    "                        html.Div([\n",
    "                                  html.Div(id='stats-table-fig')\n",
    "                                  ]),\n",
    "                        html.Div([\n",
    "                                  dash_table.DataTable(\n",
    "                                      id = 'stats-table',                                                                            \n",
    "                                      columns=[{'name': i, 'id': i, 'deletable': True, 'selectable': True} for i in ['day_sess', 'st_sess', 'ed_sess', 'mdd', 'volatility', 'growth','max_ret_time',\n",
    "                                                                                                                     'min_ret_time', 'mean_return', 'pos_return', 'up_ratio', 'down_ratio', 'index_market']],\n",
    "                                      data=[],\n",
    "                                      editable = True,\n",
    "                                      filter_action='native',\n",
    "                                      sort_action='native',\n",
    "                                      sort_mode='multi',\n",
    "                                      column_selectable='multi',\n",
    "                                      row_selectable='multi',\n",
    "                                      row_deletable=True,\n",
    "                                      selected_columns=[],\n",
    "                                      selected_rows=[],\n",
    "                                      page_action='native',\n",
    "                                      page_size = styles.PAGE_SIZE,\n",
    "                                      style_table={\n",
    "                                          'width': '75%',\n",
    "                                          'minWidth': '75%',\n",
    "                                          },\n",
    "                                      ),\n",
    "                                  ]),\n",
    "                        html.Hr(),\n",
    "                        html.Div(id='datatable-query-structure-stats', style={'whitespace': 'pre'}),\n",
    "                        html.Div(id='stats-df', style={'display': 'none'})\n",
    "                       ])\n",
    "              ])\n",
    "    return(html_res)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        layout_5\n",
    "##########################################################################################################################################################################################\n",
    "def get_layout_5():\n",
    "    html_res = \\\n",
    "    html.Div([\n",
    "              html.Div([\n",
    "                        html.Div(html.P([html.Br(),html.H2(html.B('Analysis of lag dependency between indices'))]), style=styles.STYLE_8)]),\n",
    "              html.Div([\n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('OHLC Choice'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='lag-dd-ohlc',\n",
    "                                      options=[{'label': i, 'value': i} for i in ['Open','High','Low','Close']],\n",
    "                                      value='Close',\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_9),                        \n",
    "                        html.Div([\n",
    "                                  html.Div(html.H3('Hours differential'),style=styles.STYLE_6),\n",
    "                                  dcc.Dropdown(\n",
    "                                      id='lag-dd-hours-diff',\n",
    "                                      options=[{'label': i, 'value': i} for i in range(2,12,2)],\n",
    "                                      value=2,\n",
    "                                      style=styles.STYLE_2\n",
    "                                      )\n",
    "                                      ],style=styles.STYLE_9),                        \n",
    "                        html.Div([\n",
    "                                  dcc.Graph(\n",
    "                                      id = 'lag-fig',\n",
    "                                      style=styles.STYLE_4)\n",
    "                                      ]),\n",
    "                        html.Div([\n",
    "                                  html.Div(\n",
    "                                      id='lag-table',\n",
    "                                      className='tableDiv'\n",
    "                                      )\n",
    "                                  ],style=styles.STYLE_4),\n",
    "                        ]),\n",
    "              ])\n",
    "    return(html_res)\n",
    "    \n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        layout_6\n",
    "##########################################################################################################################################################################################\n",
    "def get_layout_6():\n",
    "    html_res = \\\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Div(html.H3('OHLC choice'),style=styles.STYLE_6),\n",
    "            dcc.Dropdown(\n",
    "                id='ohlc-dropdown',\n",
    "                options=[{'label': i, 'value': i} for i in ['Open','High', 'Low', 'Close']],\n",
    "                value='Close',\n",
    "                style=styles.STYLE_2\n",
    "            )\n",
    "            ],style=styles.STYLE_12),\n",
    "        html.Div([\n",
    "            html.Div(html.H3('Index choice'),style=styles.STYLE_6),\n",
    "            dcc.Dropdown(\n",
    "                id='index-dropdown',\n",
    "                options=[{'label': i, 'value': i} for i in ['Hang Seng','Nikkei225','eMiniSP500','EuroStoxx50']],\n",
    "                value='Nikkei225',\n",
    "                style=styles.STYLE_2\n",
    "            )\n",
    "            ],style=styles.STYLE_12),\n",
    "        html.Div([\n",
    "            html.Div(html.H3('Cluster Method'),style=styles.STYLE_6),\n",
    "            dcc.Dropdown(\n",
    "                id='method-dropdown',\n",
    "                options=[{'label': i, 'value': i} for i in ['single','complete','average','weighted','centroid','median','ward']],\n",
    "                value='ward',\n",
    "                style=styles.STYLE_2\n",
    "            )\n",
    "            ],style=styles.STYLE_12),\n",
    "        html.Div([\n",
    "            html.Div(html.H3('Cluster Metric'),style=styles.STYLE_6),\n",
    "            dcc.Dropdown(\n",
    "                id='metric-dropdown',\n",
    "                options=[{'label': i, 'value': i} for i in ['euclidean','correlation','cosine','dtw']],\n",
    "                value='euclidean',\n",
    "                style=styles.STYLE_2\n",
    "            )\n",
    "            ],style=styles.STYLE_12),\n",
    "        html.Div([\n",
    "            html.Div(html.H3('Cluster max #'),style=styles.STYLE_6),\n",
    "            dcc.Dropdown(\n",
    "                id='max-cluster-dropdown',\n",
    "                options=[{'label': i, 'value': i} for i in range(int(max_cluster_rep))],\n",
    "                value=12,\n",
    "                style=styles.STYLE_2\n",
    "            )\n",
    "            ],style=styles.STYLE_12),\n",
    "        html.Div([\n",
    "                  html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('Although there was not strictly strong relationships bewteen the respective strategies and the external data (containing macro/index/commodities data, we cannot rule out completely that there could be a relationship between these time series. In fact in the assessment of the correlation matrix, we looked at common dates between the time series returns of the Strategy and the external data time series. However, there can be similarities between these time series, but hidden by the fact that the time series are shifted w.r.t each other. We look at this issue by way of clustering between the time series and introduce the Dynamic Time Warping (DTW) measure which is an elastic distance which warps two sequences non-linearly in time in order to cope with time deformations and varying speeds in time dependent data. This constrasts with other lock-step distance measures such as the Euclidean distance. In the present case we are looking at the similarity between the cumulative returns of the respective time series and the external data. We can notice that both strategies get clustered with emerging markets data along with gold. Note that the distance matrix has been computed using the DTW distance measure to account for similarity in shape between the time series. The results are robust to the clustering method, i.e. conserving the grouping of the time series. The value into parenthesis means that the are two time series at the end of the leaf of the dendrogram')),html.Br()]), style=styles.STYLE_8),\n",
    "            html.Img(id = 'cluster-plot',\n",
    "                           src = '',\n",
    "                           style=styles.STYLE_4)\n",
    "        ]),\n",
    "        html.Div([\n",
    "            html.Div(html.H3('Cluster Selected (only select those with cluster_size larger than 1 for the DTW analysis)'),style=styles.STYLE_6),\n",
    "            dcc.Dropdown(\n",
    "                id='selected-cluster-dropdown',\n",
    "                value=12,\n",
    "                style=styles.STYLE_2\n",
    "            )\n",
    "        ]),\n",
    "        html.Div(\n",
    "            id='cluster-table',\n",
    "            className='tableDiv'\n",
    "        ),\n",
    "        html.Div([\n",
    "            html.Div(html.P([html.Br(),html.H2(html.B('Dynamic time warping distance between pairs from selected cluster. The closer this distance is to 0, the more similar are the pairs'))]), style=styles.STYLE_8),\n",
    "            html.Img(id = 'dtws-uniq-plot',\n",
    "                           src = '',\n",
    "                           style=styles.STYLE_4)\n",
    "        ]),\n",
    "    ])\n",
    "    return(html_res)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        layout_7\n",
    "##########################################################################################################################################################################################\n",
    "def get_layout_7():\n",
    "    html_res = \\\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Div(html.H3('OHLC choice'),style=styles.STYLE_6),\n",
    "            dcc.Dropdown(\n",
    "                id='ohlc-adf',\n",
    "                options=[{'label': i, 'value': i} for i in ['Open','High', 'Low', 'Close']],\n",
    "                value='Close',\n",
    "                style=styles.STYLE_2\n",
    "            )\n",
    "            ],style=styles.STYLE_12),\n",
    "    html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('We look at the stationarity through the output of the Augmented Dickey-Fuller test. For each 24hr session, the minute data is used to apply the ADF test to. This is performed for each index. Then we show on the graph, all those dates that show a non-stationary behaviour are marked with a blue vertical line, no vetical line meaning (white) time series for that session is stationary. The table below the graph shows some quantitative output of the test.'))]), style=styles.STYLE_8),\n",
    "    html.Div([\n",
    "              html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('Hang Seng'))]), style=styles.STYLE_8),\n",
    "              dcc.Graph(\n",
    "                  id = 'adf-fig-1',\n",
    "                  style=styles.STYLE_13)\n",
    "              ]),\n",
    "    html.Div([\n",
    "              html.Div(html.P([html.Br(),html.H2(html.B('Nikkei225'))]), style=styles.STYLE_8),\n",
    "              dcc.Graph(\n",
    "                  id = 'adf-fig-2',\n",
    "                  style=styles.STYLE_13)\n",
    "              ]),\\\n",
    "    html.Div([\n",
    "              html.Div(html.P([html.Br(),html.H2(html.B('eMiniSP500'))]), style=styles.STYLE_8),\n",
    "              dcc.Graph(\n",
    "                  id = 'adf-fig-3',\n",
    "                  style=styles.STYLE_13),\n",
    "              ]),\n",
    "    html.Div([\n",
    "              html.Div(html.P([html.Br(),html.H2(html.B('EuroStoxx50'))]), style=styles.STYLE_8),\n",
    "              dcc.Graph(\n",
    "                  id = 'adf-fig-4',\n",
    "                  style=styles.STYLE_13)\n",
    "              ]),\n",
    "    html.Div(\n",
    "        html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('Hang Seng'))]), style=styles.STYLE_8),\n",
    "        id='adf-table-1',\n",
    "        className='tableDiv'\n",
    "        ),\n",
    "    html.Div(\n",
    "        html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('Nikkei225'))]), style=styles.STYLE_8),\n",
    "        id='adf-table-2',\n",
    "        className='tableDiv'\n",
    "        ),\n",
    "    html.Div(\n",
    "        html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('eMiniSP500'))]), style=styles.STYLE_8),\n",
    "        id='adf-table-3',\n",
    "        className='tableDiv'\n",
    "        ),\n",
    "    html.Div(\n",
    "        html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('EuroStoxx50'))]), style=styles.STYLE_8),\n",
    "        id='adf-table-4',\n",
    "        className='tableDiv'\n",
    "        ),\n",
    "    ])\n",
    "    return(html_res)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        layout_8\n",
    "##########################################################################################################################################################################################\n",
    "def get_layout_8():\n",
    "    html_res = \\\n",
    "    html.Div([\n",
    "    html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('A recurrence plot (RP) is an image obtained from a time series, representing the distances between each time point. A recurrence plot gives information about the temporal correlation of phase space points. It shows for each moment i in time, the times at which a phase space trajectory visits the same area (in that phase space) as of time j. If x_t is a vector time series, the above definition translates into x_i~x_j (or x_i=x_j within an epsilon). A recurrence is a time the trajectory returns to a location it has visited before. Vertical and horizontal lines mean that the system changes slowly in time. Diagonal lines mean that trajectories passing in the same region of phase space at different times. Parallel and perpendicular lines to the main diagonal stand for some determinism or periodicity. If neither paralllel or nor perpendicular lines we are in a situation with a pure stochastic system. Arrow shapes account for on stationary systems with strong trend.' ))]), style=styles.STYLE_8),\n",
    "   html.Div([\n",
    "             html.Div(html.H3('OHLC choice'),style=styles.STYLE_6),\n",
    "             dcc.Dropdown(\n",
    "                 id='ohlc-recplot',\n",
    "                 options=[{'label': i, 'value': i} for i in ['Open','High', 'Low', 'Close']],\n",
    "                 value='Close',\n",
    "                 style=styles.STYLE_2\n",
    "                 ),\n",
    "                 ],style=styles.STYLE_3),\n",
    "   html.Div([\n",
    "             html.Div(html.H3('Month value'),style=styles.STYLE_6),\n",
    "             dcc.Dropdown(\n",
    "                 id='month-recplot',\n",
    "                 options=[{'label': i, 'value': i} for i in range(1,styles.MONTH_VALUE)],\n",
    "                 value=1,\n",
    "                 style=styles.STYLE_2\n",
    "                 ),\n",
    "                 ],style=styles.STYLE_3),\n",
    "    html.Div([\n",
    "              html.Div(html.P([html.Br(),html.Br(),html.Br(),html.Br(),html.H2(html.B('Hang Seng'))]), style=styles.STYLE_8),\n",
    "              html.Img(id = 'recplot-fig-1',\n",
    "                       src = '',\n",
    "                       style=styles.STYLE_4)\n",
    "              ]),\n",
    "    html.Div([\n",
    "              html.Div(html.P([html.Br(),html.H2(html.B('Nikkei225'))]), style=styles.STYLE_8),\n",
    "              html.Img(id = 'recplot-fig-2',\n",
    "                       src = '',\n",
    "                       style=styles.STYLE_4)\n",
    "              ]),\n",
    "    html.Div([\n",
    "              html.Div(html.P([html.Br(),html.H2(html.B('eMiniSP500'))]), style=styles.STYLE_8),\n",
    "              html.Img(id = 'recplot-fig-3',\n",
    "                       src = '',\n",
    "                       style=styles.STYLE_4)\n",
    "              ]),\n",
    "    html.Div([\n",
    "              html.Div(html.P([html.Br(),html.H2(html.B('EuroStoxx50'))]), style=styles.STYLE_8),\n",
    "              html.Img(id = 'recplot-fig-4',\n",
    "                       src = '',\n",
    "                       style=styles.STYLE_4)\n",
    "              ]),\n",
    "    ])\n",
    "    return(html_res)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        menu\n",
    "##########################################################################################################################################################################################\n",
    "    \n",
    "def nav_menu():\n",
    "    title_all = [\"Raw plots\", \"Correlations\",\"Distribution of returns\",\n",
    "                 \"Statistics - OHLC\",\"Lag effect\",\"Clustering\",\"Stationarity test\",\"Recurrence plots\"]\n",
    "    links_all = [ dbc.NavLink(el, href='/page-'+str(i+1), id='page-'+str(i+1)+'-link', style=styles.STYLE_1) for i,el in enumerate(title_all) ] \n",
    "    nav = dbc.Nav(links_all,pills=True)\n",
    "    return(nav)\n",
    "\n",
    "###################\n",
    "# core of the app #\n",
    "###################\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = JupyterDash(__name__)\n",
    "app.config.suppress_callback_exceptions = True\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.H1(nav_menu())]),\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    html.Div(id='page-content'),    \n",
    "    ],                     \n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    [Output(f\"page-{i}-link\", \"active\") for i in range(1,styles.N_PAGES+1)],\n",
    "    [Input(\"url\", \"pathname\")],\n",
    ")\n",
    "def toggle_active_links(pathname):\n",
    "    # if pathname == \"/\":\n",
    "    #     return((True,)+(False,)*(N_PAGES-1))\n",
    "    return [pathname == f\"/page-{i}\" for i in range(1,styles.N_PAGES+1)]\n",
    "\n",
    "#################\n",
    "# stats queries #  \n",
    "#################\n",
    "@app.callback(\n",
    "    [Output('filter-query-input-stats', 'style'),\n",
    "     Output('filter-query-output-stats', 'style')],\n",
    "    [Input('filter-query-read-write-stats', 'value')]\n",
    ")\n",
    "def query_input_output(val):\n",
    "    input_style = {'width': '100%'}\n",
    "    output_style = {}\n",
    "    if val == 'read':\n",
    "        input_style.update(display='none')\n",
    "        output_style.update(display='inline-block')\n",
    "    else:\n",
    "        input_style.update(display='inline-block')\n",
    "        output_style.update(display='none')\n",
    "    return(input_style, output_style)\n",
    "\n",
    "@app.callback(\n",
    "    Output('stats-table', 'filter_query'),\n",
    "    [Input('filter-query-input-stats', 'value')]\n",
    ")\n",
    "def write_query(query):\n",
    "    if query is None:\n",
    "        return('')\n",
    "    return(query)\n",
    "\n",
    "@app.callback(\n",
    "    Output('filter-query-output-stats', 'children'),\n",
    "    [Input('stats-table', 'filter_query')]\n",
    ")\n",
    "def read_query(query):\n",
    "    if query is None:\n",
    "        return('No filter query')\n",
    "    return dcc.Markdown('`filter_query = \"{}\"`'.format(query))\n",
    "\n",
    "@app.callback(\n",
    "    Output('datatable-query-structure-stats', 'children'),\n",
    "    [Input('stats-table', 'derived_filter_query_structure')]\n",
    ")\n",
    "def display_query(query):\n",
    "    if query is None:\n",
    "        return('')\n",
    "    return html.Details([\n",
    "        html.Summary('Derived filter query structure'),\n",
    "        html.Div(dcc.Markdown('''```json{}```'''.format(json.dumps(query, indent=4))))\n",
    "    ])\n",
    "\n",
    "@app.callback(\n",
    "    Output('selected-cluster-dropdown', 'options'),\n",
    "    [Input('max-cluster-dropdown', 'value')]\n",
    ")\n",
    "def update_cluster_dropdown(max_cluster_val):\n",
    "    options=[{'label': opt, 'value': opt} for opt in range(1,int(max_cluster_val)+1)]\n",
    "    return(options)\n",
    "\n",
    "@app.callback(\n",
    "    Output('metric-dropdown', 'options'),\n",
    "    [Input('method-dropdown', 'value')]\n",
    ")\n",
    "def update_cluster_dropdown(method_dropdown_val):\n",
    "    if(method_dropdown_val == 'centroid' or method_dropdown_val == 'median' or method_dropdown_val == 'ward'):\n",
    "        options=[{'label': 'euclidean', 'value':'euclidean'}]\n",
    "    else:\n",
    "        options=[{'label': opt, 'value': opt} for opt in ['euclidean','correlation','cosine','dtw']]\n",
    "    return(options)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        page_1\n",
    "##########################################################################################################################################################################################\n",
    "@app.callback(\n",
    "    Output('ohlc-dd-mvavg', 'options'),\n",
    "    [Input('ohlc-dd-freq', 'value')]\n",
    ")\n",
    "def update_mvavg_dropdown_1(freq):\n",
    "    if(freq == 'daily'):\n",
    "        options=[{'label': str(i)+'D', 'value': int(i)} for i in [15,30,60]]\n",
    "    elif(freq == '15min'):\n",
    "        options=[{'label': str(i//60)+'hr', 'value': str(i)+'T'} for i in [60,120,240,720,1440]]\n",
    "    return(options)\n",
    "   \n",
    "page_1_layout = html.Div([ get_layout_1() ])\n",
    "\n",
    "@app.callback(Output('ohlc', 'figure'),\n",
    "              [Input('ohlc-dd-freq', 'value'),\n",
    "               Input('ohlc-dd-index', 'value'),\n",
    "               Input('ohlc-dd-mvavg', 'value'),],\n",
    ")\n",
    "def update_fig_1(freq,index_val,wnd):\n",
    "    df = get_df_choice(freq,index_val,wnd)\n",
    "\n",
    "    fig = functions.fig_raw_plot(df,freq,index_val,wnd)\n",
    "    return(fig)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        page_2\n",
    "##########################################################################################################################################################################################\n",
    "page_2_layout = html.Div([ get_layout_2() ])\n",
    "\n",
    "@app.callback([Output('corr', 'figure'),\n",
    "               Output('corr-table', 'children')],\n",
    "              [Input('htpp-dd-freq','value'),\n",
    "               Input('htpp-dd-thrs', 'value')]\n",
    ")              \n",
    "def update_fig_2(freq,vthreshold):\n",
    "    if(freq == 'daily'):\n",
    "        mask_hk = (df_hk_daily.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_hk_daily.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "        mask_nikkei = (df_nikkei_daily.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_nikkei_daily.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "        mask_spmini500 = (df_spmini500_daily.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_spmini500_daily.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "        mask_eustoxx50 = (df_eustoxx50_daily.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_eustoxx50_daily.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "        mask_vix= (df_vix_daily.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_vix_daily.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "\n",
    "        df_hk_select = df_hk_daily.loc[mask_hk]\n",
    "        df_nikkei_select = df_nikkei_daily.loc[mask_nikkei]\n",
    "        df_spmini500_select = df_spmini500_daily.loc[mask_spmini500]\n",
    "        df_eustoxx50_select = df_eustoxx50_daily.loc[mask_eustoxx50]\n",
    "        df_vix_select = df_vix_daily.loc[mask_vix]\n",
    "    elif(freq == '15min'):\n",
    "        mask_hk = (df_hk_minute.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_hk_minute.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "        mask_nikkei = (df_nikkei_minute.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_nikkei_minute.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "        mask_spmini500 = (df_spmini500_minute.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_spmini500_minute.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "        mask_eustoxx50 = (df_eustoxx50_minute.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_eustoxx50_minute.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "        mask_vix= (df_vix_minute.index >= pd.to_datetime('2020-05-09 00:00:00').tz_localize('UTC')) & (df_vix_minute.index < pd.to_datetime('2020-05-23 00:00:00').tz_localize('UTC'))\n",
    "\n",
    "        df_nikkei_select = df_nikkei_minute.loc[mask_nikkei]\n",
    "        df_hk_select = df_hk_minute.loc[mask_hk]\n",
    "        df_spmini500_select = df_spmini500_minute.loc[mask_spmini500]\n",
    "        df_eustoxx50_select = df_eustoxx50_minute.loc[mask_eustoxx50]\n",
    "        df_vix_select = df_vix_minute.loc[mask_vix]\n",
    "        \n",
    "    df_hk_select.columns = [ el+'_hk' for el in df_hk_select.columns ]\n",
    "    df_nikkei_select.columns = [ el+'_nk' for el in df_nikkei_select.columns ]\n",
    "    df_spmini500_select.columns = [ el+'_us' for el in df_spmini500_select.columns ]\n",
    "    df_eustoxx50_select.columns = [ el+'_eu' for el in df_eustoxx50_select.columns ]\n",
    "    df_vix_select.columns = [ el+'_vix' for el in df_vix_select.columns ]\n",
    "\n",
    "    df_all = pd.concat([df_hk_select,df_nikkei_select,df_spmini500_select,df_eustoxx50_select,df_vix_select],axis=1).dropna()\n",
    "\n",
    "    # correlation\n",
    "    df_corr_all = df_all[[el for el in df_all.columns if 'H-L' not in el]]    \n",
    "    fig_corr, corr_matrix_filtered = functions.data_pairheat(df_corr_all,'Correlation matrix for the time series of all indices',vthreshold)\n",
    "\n",
    "    corr_matrix_dct = corr_matrix_filtered.unstack().to_dict()\n",
    "    corr_matrix_dct = {k: v for k, v in corr_matrix_dct.items() if pd.Series(v).notna().all()}\n",
    "    corr_matrix_dct_sorted = {k: v for k, v in sorted(corr_matrix_dct.items(), key=lambda x: x[1], reverse=True)}\n",
    "\n",
    "    pairs_1 = [x[0] for x in list(corr_matrix_dct_sorted.keys())]\n",
    "    pairs_2 = [x[1] for x in list(corr_matrix_dct_sorted.keys())]\n",
    "    values = [ round(el,4) for el in list(corr_matrix_dct_sorted.values()) ]\n",
    "    res = pd.DataFrame.from_dict({'pair_1': pairs_1,'pair_2': pairs_2,'correlation': values})  \n",
    "    df_res_table = functions.df_to_table(res)\n",
    "    \n",
    "    return(fig_corr,df_res_table)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        page_3\n",
    "##########################################################################################################################################################################################\n",
    "page_3_layout = html.Div([ get_layout_3() ])\n",
    "\n",
    "@app.callback([Output('ret-dist-comp', 'figure'),\n",
    "               Output('log-ret-dist-comp', 'figure')],\n",
    "              [Input('ret-dd-idx-1', 'value'),\n",
    "               Input('ret-dd-idx-2', 'value'),\n",
    "               Input('ret-dd-day-1', 'value'),\n",
    "               Input('ret-dd-month-1', 'value'),\n",
    "               Input('ret-dd-day-2', 'value'),\n",
    "               Input('ret-dd-month-2', 'value'),\n",
    "               Input('ret-dd-ohlc-1', 'value'),\n",
    "               Input('ret-dd-ohlc-2', 'value')]\n",
    ")\n",
    "def update_fig_3(index_val_1,index_val_2,day_1,month_1,day_2,month_2,ohlc_1,ohlc_2):\n",
    "    date_1_low = pd.to_datetime('2020-'\"{:02d}\"'-'\"{:02d}\".format(month_1,day_1)+' 00:00:00') \n",
    "    date_1_up = pd.to_datetime('2020-'\"{:02d}\"'-'\"{:02d}\".format(month_1,day_1)+' 23:59:59') \n",
    "    date_2_low = pd.to_datetime('2020-'\"{:02d}\"'-'\"{:02d}\".format(month_2,day_2)+' 00:00:00')\n",
    "    date_2_up = pd.to_datetime('2020-'\"{:02d}\"'-'\"{:02d}\".format(month_2,day_2)+' 23:59:59')\n",
    "    \n",
    "    mask_date_hk_1 = (df_hk_minute.index >= date_1_low.tz_localize('UTC')) & (df_hk_minute.index <= date_1_up.tz_localize('UTC'))\n",
    "    mask_date_hk_2 = (df_hk_minute.index >= date_2_low.tz_localize('UTC')) & (df_hk_minute.index <= date_2_up.tz_localize('UTC'))\n",
    "    \n",
    "    mask_date_nk_1 = (df_nikkei_minute.index >= date_1_low.tz_localize('UTC')) & (df_nikkei_minute.index <= date_1_up.tz_localize('UTC'))\n",
    "    mask_date_nk_2 = (df_nikkei_minute.index >= date_2_low.tz_localize('UTC')) & (df_nikkei_minute.index <= date_2_up.tz_localize('UTC'))\n",
    "\n",
    "    mask_date_sp_1 = (df_spmini500_minute.index >= date_1_low.tz_localize('UTC')) & (df_spmini500_minute.index <= date_1_up.tz_localize('UTC'))\n",
    "    mask_date_sp_2 = (df_spmini500_minute.index >= date_2_low.tz_localize('UTC')) & (df_spmini500_minute.index <= date_2_up.tz_localize('UTC'))\n",
    "\n",
    "    mask_date_eu_1 = (df_eustoxx50_minute.index >= date_1_low.tz_localize('UTC')) & (df_eustoxx50_minute.index <= date_1_up.tz_localize('UTC'))\n",
    "    mask_date_eu_2 = (df_eustoxx50_minute.index >= date_2_low.tz_localize('UTC')) & (df_eustoxx50_minute.index <= date_2_up.tz_localize('UTC'))\n",
    "\n",
    "    mask_date_vix_1 = (df_vix_minute.index >= date_1_low.tz_localize('UTC')) & (df_vix_minute.index <= date_1_up.tz_localize('UTC'))\n",
    "    mask_date_vix_2 = (df_vix_minute.index >= date_2_low.tz_localize('UTC')) & (df_vix_minute.index <= date_2_up.tz_localize('UTC'))\n",
    "    \n",
    "    df_hk_date_1 = df_hk_minute.loc[mask_date_hk_1]\n",
    "    df_hk_date_2 = df_hk_minute.loc[mask_date_hk_2]\n",
    "\n",
    "    df_nk_date_1 = df_nikkei_minute.loc[mask_date_nk_1]\n",
    "    df_nk_date_2 = df_nikkei_minute.loc[mask_date_nk_2]\n",
    "\n",
    "    df_sp_date_1 = df_spmini500_minute.loc[mask_date_sp_1]\n",
    "    df_sp_date_2 = df_spmini500_minute.loc[mask_date_sp_2]\n",
    "\n",
    "    df_eu_date_1 = df_eustoxx50_minute.loc[mask_date_eu_1]\n",
    "    df_eu_date_2 = df_eustoxx50_minute.loc[mask_date_eu_2]\n",
    "\n",
    "    df_vix_date_1 = df_vix_minute.loc[mask_date_vix_1]\n",
    "    df_vix_date_2 = df_vix_minute.loc[mask_date_vix_2]\n",
    "    \n",
    "    fig1,fig2 = functions.fig_dist_comp(index_val_1,index_val_2,df_hk_date_1,df_hk_date_2,\n",
    "                                df_nk_date_1,df_nk_date_2,\n",
    "                                df_sp_date_1,df_sp_date_2,\n",
    "                                df_eu_date_1,df_eu_date_2,\n",
    "                                df_vix_date_1,df_vix_date_2,\n",
    "                                ohlc_1,ohlc_2)\n",
    "    return(fig1,fig2)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        page_4\n",
    "##########################################################################################################################################################################################\n",
    "page_4_layout = html.Div([ get_layout_4() ])\n",
    "\n",
    "@app.callback(Output('stats-table-fig', 'children'),\n",
    "              [Input('stats-table', 'derived_virtual_data'),\n",
    "               Input('stats-table', 'derived_virtual_selected_rows'),\n",
    "               Input('stats-df', 'data')])\n",
    "def update_graphs(rows, derived_virtual_selected_rows, stats_df):\n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "    \n",
    "    dff = pd.read_json(stats_df) if rows is None else pd.DataFrame(rows)\n",
    "    colors = ['#7FDBFF' if i in derived_virtual_selected_rows else '#0074D9' for i in range(len(dff))]\n",
    "\n",
    "    return([\n",
    "            dcc.Graph(\n",
    "                id=column,\n",
    "                figure={\n",
    "                    'data': [\n",
    "                        {\n",
    "                            'x': dff['day_sess'],\n",
    "                            'y': dff[column],\n",
    "                            'type': 'bar',\n",
    "                            'marker': {'color': colors},\n",
    "                        }\n",
    "                        ],\n",
    "                    'layout': {\n",
    "                        'xaxis': {'automargin': True},\n",
    "                        'yaxis': {\n",
    "                        'automargin': True,\n",
    "                        'title': {'text': column},\n",
    "                        'barmode':'stack',\n",
    "                        },\n",
    "                        'height': 250,\n",
    "                        },\n",
    "                },\n",
    "        )\n",
    "        for column in ['mean_return','up_ratio','down_ratio','volatility', 'mdd'] if column in dff])\n",
    "\n",
    "@app.callback(Output('stats-table', 'data'),\n",
    "              [Input('stats-dd-ohlc', 'value')],\n",
    ")\n",
    "def get_dataframe_stats_0(ohlc):\n",
    "    df_res = table_stats_ohlc(df_hk_minute,df_nikkei_minute,df_spmini500_minute,df_eustoxx50_minute,ohlc)\n",
    "    return(df_res.to_dict('rows'))\n",
    "\n",
    "@app.callback(Output('stats-df', 'data'),\n",
    "              [Input('stats-dd-ohlc', 'value')],\n",
    ")\n",
    "def get_dataframe_stats_1(ohlc):\n",
    "    df_res = table_stats_ohlc(df_hk_minute,df_nikkei_minute,df_spmini500_minute,df_eustoxx50_minute,ohlc)\n",
    "    return(df_res.to_json())\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        page_5\n",
    "##########################################################################################################################################################################################\n",
    "page_5_layout = html.Div([ get_layout_5() ])\n",
    "\n",
    "@app.callback([Output('lag-fig', 'figure'),\n",
    "               Output('lag-table', 'children')],\n",
    "              [Input('lag-dd-ohlc', 'value'),\n",
    "               Input('lag-dd-hours-diff', 'value')]\n",
    ")              \n",
    "def update_fig_5(ohlc,lag_hours):\n",
    "    df_hk,df_nk,df_sp,df_eu,ohlc,hours_diff = df_hk_minute,df_nikkei_minute,df_spmini500_minute,df_eustoxx50_minute,ohlc,lag_hours\n",
    "    \n",
    "    df_all_last_hang,df_all_last_nikkei,df_all_last_spmini500,df_all_last_eustoxx50,df_all_first_hang,df_all_first_nikkei,df_all_first_spmini500,df_all_first_eustoxx50 = \\\n",
    "      get_all_first_last(df_hk,df_nk,df_sp,df_eu,ohlc,hours_diff)\n",
    "\n",
    "    # dataframe with all data\n",
    "    pairs_all = ['Hang_Seng_last','Nikkei225_last','eMiniSP500_last','EuroStoxx50_last',\n",
    "                 'Hang_Seng_first','Nikkei225_first','eMiniSP500_first','EuroStoxx50_first']\n",
    "\n",
    "    df_all_first_last = pd.concat([df_all_last_hang,df_all_last_nikkei,df_all_last_spmini500,df_all_last_eustoxx50,\n",
    "                                   df_all_first_hang,df_all_first_nikkei,df_all_first_spmini500,df_all_first_eustoxx50],axis=1)\n",
    "    df_all_first_last.columns = pairs_all\n",
    "    \n",
    "    pairs_comb = [ el[0]+'__'+el[1] for el in list(itertools.combinations(pairs_all,2)) ]\n",
    "    pairs_dfs = [(df_all_last_hang, df_all_last_nikkei), (df_all_last_hang, df_all_last_spmini500), (df_all_last_hang, df_all_last_eustoxx50), (df_all_last_hang, df_all_first_hang),\n",
    "                 (df_all_last_hang, df_all_first_nikkei), (df_all_last_hang, df_all_first_spmini500), (df_all_last_hang, df_all_first_eustoxx50),(df_all_last_nikkei, df_all_last_spmini500),\n",
    "                 (df_all_last_nikkei, df_all_last_eustoxx50), (df_all_last_nikkei, df_all_first_hang), (df_all_last_nikkei, df_all_first_nikkei), (df_all_last_nikkei, df_all_first_spmini500),\n",
    "                 (df_all_last_nikkei, df_all_first_eustoxx50), (df_all_last_spmini500, df_all_last_eustoxx50), (df_all_last_spmini500, df_all_first_hang), (df_all_last_spmini500, df_all_first_nikkei),\n",
    "                 (df_all_last_spmini500, df_all_first_spmini500), (df_all_last_spmini500, df_all_first_eustoxx50),(df_all_last_eustoxx50, df_all_first_hang), (df_all_last_eustoxx50, df_all_first_nikkei),\n",
    "                 (df_all_last_eustoxx50, df_all_first_spmini500), (df_all_last_eustoxx50, df_all_first_eustoxx50), (df_all_first_hang, df_all_first_nikkei), (df_all_first_hang, df_all_first_spmini500),\n",
    "                 (df_all_first_hang, df_all_first_eustoxx50), (df_all_first_nikkei, df_all_first_spmini500), (df_all_first_nikkei, df_all_first_eustoxx50), (df_all_first_spmini500, df_all_first_eustoxx50)]\n",
    "\n",
    "    dct_pairs = dict(zip(pairs_comb,pairs_dfs))\n",
    "\n",
    "    df_summary = pd.DataFrame(index=pairs_comb,columns=['same direction','opposite direction'])\n",
    "    for i,(k,v) in enumerate(dct_pairs.items()):\n",
    "        res = np.sign(v[0]['growth'].multiply(v[1]['growth'],axis='index'))\n",
    "        df_summary.iloc[i] = [len(res[res==1]),len(res[res==-1])]\n",
    "\n",
    "    df_summary['pair_1'] = [el.split('__')[0] for el in df_summary.index]\n",
    "    df_summary['pair_2'] = [el.split('__')[1] for el in df_summary.index]\n",
    "\n",
    "    lag_table = functions.df_to_table(df_summary[::-1])\n",
    "    \n",
    "    # plot results\n",
    "    data_1_last = [dict(\n",
    "        type = 'bar',\n",
    "        x = df_all_last_hang.index,\n",
    "        y = df_all_last_hang['growth'],\n",
    "        name = 'Hang Seng - Last',\n",
    "    )]\n",
    "\n",
    "    layout = dict()\n",
    "    fig = dict(data=data_1_last,layout=layout)\n",
    "    \n",
    "    fig['layout'] = dict()\n",
    "    fig['layout']['plot_bgcolor'] = 'rgb(250, 250, 250)'\n",
    "    fig['layout']['xaxis'] = {'automargin': True}\n",
    "    fig['layout']['yaxis'] = dict(automargin=True,title='cumulative return')\n",
    "    fig['layout']['width'] = 1800\n",
    "    fig['layout']['height'] = 1200\n",
    "\n",
    "    data_2_last = dict(\n",
    "        type = 'bar',\n",
    "        x = df_all_last_nikkei.index,\n",
    "        y = df_all_last_nikkei['growth'],\n",
    "        name = 'Nikkei225 - Last',\n",
    "    )\n",
    "\n",
    "    data_3_last = dict(\n",
    "        type = 'bar',\n",
    "        x = df_all_last_spmini500.index,\n",
    "        y = df_all_last_spmini500['growth'],\n",
    "        name = 'eMini SP500 - Last',\n",
    "    )\n",
    "\n",
    "    data_4_last = dict(\n",
    "        type = 'bar',\n",
    "        x = df_all_last_eustoxx50.index,\n",
    "        y = df_all_last_eustoxx50['growth'],\n",
    "        name = 'Eurostoxx50 - Last',\n",
    "    )\n",
    "\n",
    "    # first\n",
    "    data_1_first = dict(\n",
    "        type = 'bar',\n",
    "        x = df_all_first_hang.index,\n",
    "        y = df_all_first_hang['growth'],\n",
    "        name = 'Hang Seng - First',\n",
    "    )\n",
    "    \n",
    "    data_2_first = dict(\n",
    "        type = 'bar',\n",
    "        x = df_all_first_nikkei.index,\n",
    "        y = df_all_first_nikkei['growth'],\n",
    "        name = 'Nikkei225 - First',\n",
    "    )\n",
    "\n",
    "    data_3_first = dict(\n",
    "        type = 'bar',\n",
    "        x = df_all_first_spmini500.index,\n",
    "        y = df_all_first_spmini500['growth'],\n",
    "        name = 'eMini SP500 - First',\n",
    "    )\n",
    "\n",
    "    data_4_first = dict(\n",
    "        type = 'bar',\n",
    "        x = df_all_first_eustoxx50.index,\n",
    "        y = df_all_first_eustoxx50['growth'],\n",
    "        name = 'Eurostoxx50 - First',\n",
    "    )\n",
    "\n",
    "    fig['data'].append(data_2_last)\n",
    "    fig['data'].append(data_3_last)\n",
    "    fig['data'].append(data_4_last)\n",
    "    fig['data'].append(data_1_first)\n",
    "    fig['data'].append(data_2_first)\n",
    "    fig['data'].append(data_3_first)\n",
    "    fig['data'].append(data_4_first)\n",
    "\n",
    "    return(fig,lag_table)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        page_6\n",
    "##########################################################################################################################################################################################\n",
    "page_6_layout = html.Div([ get_layout_6() ])\n",
    "\n",
    "@app.callback([Output('cluster-plot', 'src'),\n",
    "               Output('cluster-table', 'children'),\n",
    "               Output('dtws-uniq-plot', 'src'),\n",
    "               ],\n",
    "              [Input(\"index-dropdown\", \"value\"),\n",
    "               Input(\"ohlc-dropdown\", \"value\"),\n",
    "               Input(\"method-dropdown\", \"value\"),\n",
    "               Input(\"metric-dropdown\", \"value\"),\n",
    "               Input(\"max-cluster-dropdown\", \"value\"),\n",
    "               Input(\"selected-cluster-dropdown\", \"value\")\n",
    "              ]\n",
    ")\n",
    "def update_fig_6(index_val,ohlc,method,metric,max_cluster,selected_cluster):\n",
    "    days_all = all_common_dates()\n",
    "    \n",
    "    df_hang_select_all = []\n",
    "    df_nikkei_select_all = []\n",
    "    df_spmini500_select_all = []\n",
    "    df_eustoxx50_select_all = []\n",
    "    \n",
    "    # for each daily date take a full 24hr session (for all indices)\n",
    "    for i,el in enumerate(days_all):\n",
    "        sd = pd.to_datetime(str(el.date()) + ' 00:00:00').tz_localize('UTC')\n",
    "        ed = pd.to_datetime(str(el.date()) + ' 23:59:59').tz_localize('UTC')\n",
    "        \n",
    "        mask_hang = (df_hk_minute.index >= sd) & (df_hk_minute.index <= ed)\n",
    "        mask_nikkei = (df_nikkei_minute.index >= sd) & (df_nikkei_minute.index <= ed)\n",
    "        mask_spmini500 = (df_spmini500_minute.index >= sd) & (df_spmini500_minute.index <= ed)\n",
    "        mask_eustoxx50 = (df_eustoxx50_minute.index >= sd) & (df_eustoxx50_minute.index <= ed)\n",
    "\n",
    "        df_hang_select = df_hk_minute.loc[mask_hang]\n",
    "        df_nikkei_select = df_nikkei_minute.loc[mask_nikkei]\n",
    "        df_spmini500_select = df_spmini500_minute.loc[mask_spmini500]\n",
    "        df_eustoxx50_select = df_eustoxx50_minute.loc[mask_eustoxx50]\n",
    "\n",
    "        df_hang_select['rate_ret'] = df_hang_select[ohlc].pct_change()\n",
    "        df_nikkei_select['rate_ret'] = df_nikkei_select[ohlc].pct_change()\n",
    "        df_spmini500_select['rate_ret'] = df_spmini500_select[ohlc].pct_change()\n",
    "        df_eustoxx50_select['rate_ret'] = df_eustoxx50_select[ohlc].pct_change()\n",
    "\n",
    "        df_hang_select.dropna(inplace=True)\n",
    "        df_nikkei_select.dropna(inplace=True)\n",
    "        df_spmini500_select.dropna(inplace=True)\n",
    "        df_eustoxx50_select.dropna(inplace=True)\n",
    "\n",
    "        df_hang_select_all.append(df_hang_select['rate_ret'].T)\n",
    "        df_nikkei_select_all.append(df_nikkei_select['rate_ret'].T)\n",
    "        df_spmini500_select_all.append(df_spmini500_select['rate_ret'].T)\n",
    "        df_eustoxx50_select_all.append(df_eustoxx50_select['rate_ret'].T)\n",
    "\n",
    "    df_hang_merge = pd.concat(df_hang_select_all,axis=1)\n",
    "    df_nikkei_merge = pd.concat(df_nikkei_select_all,axis=1)\n",
    "    df_spmini500_merge = pd.concat(df_spmini500_select_all,axis=1)\n",
    "    df_eustoxx50_merge = pd.concat(df_eustoxx50_select_all,axis=1)\n",
    "\n",
    "    df_hang_merge.fillna(0,inplace=True)\n",
    "    df_nikkei_merge.fillna(0,inplace=True)\n",
    "    df_spmini500_merge.fillna(0,inplace=True)\n",
    "    df_eustoxx50_merge.fillna(0,inplace=True)\n",
    "\n",
    "    df_hang_merge.columns = [\"{:02d}\"'-'\"{:02d}\".format(el.month,el.day)  for el in days_all ]\n",
    "    df_nikkei_merge.columns = [\"{:02d}\"'-'\"{:02d}\".format(el.month,el.day)  for el in days_all ]\n",
    "    df_spmini500_merge.columns = [\"{:02d}\"'-'\"{:02d}\".format(el.month,el.day)  for el in days_all ]\n",
    "    df_eustoxx50_merge.columns = [\"{:02d}\"'-'\"{:02d}\".format(el.month,el.day)  for el in days_all ]\n",
    "\n",
    "    if(index_val == 'Hang Seng'):\n",
    "        encoded_image_0, df_res, encoded_image_1 = functions.cluster_draw(df_hang_merge.T, method, metric, max_cluster, selected_cluster, 5)\n",
    "    elif(index_val == 'Nikkei225'):\n",
    "        encoded_image_0, df_res, encoded_image_1 = functions.cluster_draw(df_nikkei_merge.T, method, metric, max_cluster, selected_cluster, 5)\n",
    "    elif(index_val == 'eMiniSP500'):\n",
    "        encoded_image_0, df_res, encoded_image_1 = functions.cluster_draw(df_spmini500_merge.T, method, metric, max_cluster, selected_cluster, 5)\n",
    "    elif(index_val == 'EuroStoxx50'):\n",
    "        encoded_image_0, df_res, encoded_image_1 = functions.cluster_draw(df_eustoxx50_merge.T, method, metric, max_cluster, selected_cluster, 5)\n",
    "            \n",
    "    cluster_html_table = functions.df_to_table(df_res)                                                                  \n",
    "    return(encoded_image_0, cluster_html_table,encoded_image_1)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        page_7\n",
    "##########################################################################################################################################################################################\n",
    "page_7_layout = html.Div([ get_layout_7() ])\n",
    "\n",
    "@app.callback([Output('adf-fig-1', 'figure'),\n",
    "               Output('adf-fig-2', 'figure'),\n",
    "               Output('adf-fig-3', 'figure'),\n",
    "               Output('adf-fig-4', 'figure'),\n",
    "               Output('adf-table-1', 'children'),\n",
    "               Output('adf-table-2', 'children'),\n",
    "               Output('adf-table-3', 'children'),\n",
    "               Output('adf-table-4', 'children')],\n",
    "              [Input(\"ohlc-adf\", \"value\")]\n",
    ")\n",
    "def update_fig_7(ohlc):\n",
    "    days_all = all_common_dates()\n",
    "    df_hang_select_all,df_nikkei_select_all,df_spmini500_select_all,df_eustoxx50_select_all = stats_dataframes(ohlc,days_all)\n",
    "\n",
    "    df_res_hang = pd.DataFrame.from_dict([ Helper.adfuller_test(el.values) for el in df_hang_select_all ])\n",
    "    df_res_nikkei = pd.DataFrame.from_dict([ Helper.adfuller_test(el.values) for el in df_nikkei_select_all ])\n",
    "    df_res_spmini500 = pd.DataFrame.from_dict([ Helper.adfuller_test(el.values) for el in df_spmini500_select_all ])\n",
    "    df_res_eustoxx50 = pd.DataFrame.from_dict([ Helper.adfuller_test(el.values) for el in df_eustoxx50_select_all ])\n",
    "\n",
    "    df_res_hang['Dates'] = [ \"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day) for el in days_all ]\n",
    "    df_res_nikkei['Dates'] = [ \"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day) for el in days_all ]\n",
    "    df_res_spmini500['Dates'] = [ \"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day) for el in days_all ]\n",
    "    df_res_eustoxx50['Dates'] = [ \"{:02d}\"'-'\"{:02d}\"'-'\"{:02d}\".format(el.year,el.month,el.day) for el in days_all ]\n",
    "\n",
    "    fig_1,fig_2,fig_3,fig_4 = functions.fig_adf(df_res_hang,df_res_nikkei,df_res_spmini500,df_res_eustoxx50)\n",
    "    adf_html_table_hang = functions.df_to_table(df_res_hang.head())\n",
    "    adf_html_table_nikkei = functions.df_to_table(df_res_nikkei.head())\n",
    "    adf_html_table_spmini500 = functions.df_to_table(df_res_spmini500.head())\n",
    "    adf_html_table_eustoxx50 = functions.df_to_table(df_res_eustoxx50.head())\n",
    "    \n",
    "    return(fig_1,fig_2,fig_3,fig_4,adf_html_table_hang,adf_html_table_nikkei,adf_html_table_spmini500,adf_html_table_eustoxx50)\n",
    "\n",
    "##########################################################################################################################################################################################\n",
    "#                                                                                        page_8\n",
    "##########################################################################################################################################################################################\n",
    "page_8_layout = html.Div([ get_layout_8() ])\n",
    "\n",
    "@app.callback([Output('recplot-fig-1', 'src'),\n",
    "               Output('recplot-fig-2', 'src'),\n",
    "               Output('recplot-fig-3', 'src'),\n",
    "               Output('recplot-fig-4', 'src')],\n",
    "              [Input(\"ohlc-recplot\", \"value\"),\n",
    "               Input(\"month-recplot\", \"value\")]\n",
    ")\n",
    "def update_fig_8(ohlc,month_val):\n",
    "    days_all = all_common_dates()\n",
    "    df_hang_select_all,df_nikkei_select_all,df_spmini500_select_all,df_eustoxx50_select_all = stats_dataframes_ohlc(ohlc,days_all)\n",
    "\n",
    "    df_hang_merge = pd.concat(df_hang_select_all,axis=0) # .to_frame()\n",
    "    df_nikkei_merge = pd.concat(df_nikkei_select_all,axis=0) # .to_frame()\n",
    "    df_spmini500_merge = pd.concat(df_spmini500_select_all,axis=0) # .to_frame()\n",
    "    df_eustoxx50_merge = pd.concat(df_eustoxx50_select_all,axis=0) # .to_frame()\n",
    "\n",
    "    df_hang_merge['month'] = [ el.date().month for el in df_hang_merge.index ]\n",
    "    df_nikkei_merge['month'] = [ el.date().month for el in df_nikkei_merge.index ]\n",
    "    df_spmini500_merge['month'] = [ el.date().month for el in df_spmini500_merge.index ]\n",
    "    df_eustoxx50_merge['month'] = [ el.date().month for el in df_eustoxx50_merge.index ]\n",
    "    \n",
    "    df_hang_merge['day'] = [ el.date().day for el in df_hang_merge.index ]\n",
    "    df_nikkei_merge['day'] = [ el.date().day for el in df_nikkei_merge.index ]\n",
    "    df_spmini500_merge['day'] = [ el.date().day for el in df_spmini500_merge.index ]\n",
    "    df_eustoxx50_merge['day'] = [ el.date().day for el in df_eustoxx50_merge.index]\n",
    "\n",
    "    df_hang_merge = df_hang_merge[(df_hang_merge['month']==month_val)]\n",
    "    df_nikkei_merge = df_nikkei_merge[(df_nikkei_merge['month']==month_val)]\n",
    "    df_spmini500_merge = df_spmini500_merge[(df_spmini500_merge['month']==month_val)]\n",
    "    df_eustoxx50_merge = df_eustoxx50_merge[(df_eustoxx50_merge['month']==month_val)]\n",
    "\n",
    "    clusterlib.rec_plot(df_hang_merge[ohlc],'HangSeng',ohlc)\n",
    "    clusterlib.rec_plot(df_nikkei_merge[ohlc],'Nikkei225',ohlc)\n",
    "    clusterlib.rec_plot(df_spmini500_merge[ohlc],'eMiniSP500',ohlc)\n",
    "    clusterlib.rec_plot(df_eustoxx50_merge[ohlc],'EuroStoxx50',ohlc)\n",
    "\n",
    "    filename_1 = 'data_out/rec_plot_'+str('HangSeng'.lower())+'_'+str(ohlc.lower())\n",
    "    filename_2 = 'data_out/rec_plot_'+str('Nikkei225'.lower())+'_'+str(ohlc.lower())\n",
    "    filename_3 = 'data_out/rec_plot_'+str('eMiniSP500'.lower())+'_'+str(ohlc.lower())\n",
    "    filename_4 = 'data_out/rec_plot_'+str('EuroStoxx50'.lower())+'_'+str(ohlc.lower())\n",
    "\n",
    "    encoded_image_1, encoded_image_2, encoded_image_3, encoded_image_4 = functions.plot_recplot(filename_1,filename_2,filename_3,filename_4)\n",
    "    return(encoded_image_1, encoded_image_2, encoded_image_3, encoded_image_4)\n",
    "    \n",
    "####################################################################################################################################################################################\n",
    "#                                                                                            page display                                                                          # \n",
    "####################################################################################################################################################################################\n",
    "@app.callback(dash.dependencies.Output('page-content', 'children'),\n",
    "              [dash.dependencies.Input('url', 'pathname')])\n",
    "def display_page(pathname):\n",
    "    if pathname == '/page-1':\n",
    "        return page_1_layout\n",
    "    elif pathname == '/page-2':\n",
    "        return page_2_layout\n",
    "    elif pathname == '/page-3':\n",
    "        return page_3_layout\n",
    "    elif pathname == '/page-4':\n",
    "        return page_4_layout\n",
    "    elif pathname == '/page-5':\n",
    "        return page_5_layout\n",
    "    elif pathname == '/page-6':\n",
    "        return page_6_layout\n",
    "    elif pathname == '/page-7':\n",
    "        return page_7_layout\n",
    "    elif pathname == '/page-8':\n",
    "        return page_8_layout\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run_server(mode='external')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
